{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network For Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the data from the other proejct into memory by using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>female</th>\n",
       "      <th>Col</th>\n",
       "      <th>Don</th>\n",
       "      <th>Dona</th>\n",
       "      <th>Dr</th>\n",
       "      <th>...</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Rev</th>\n",
       "      <th>Sir</th>\n",
       "      <th>the Countess</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>class-2</th>\n",
       "      <th>class-3</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1269</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1013</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Age  sibsp  parch     fare  female   Col   Don   Dona  \\\n",
       "1226        1226  19.000000      0      0   7.8958       0     0     0      0   \n",
       "1269        1269  33.000000      0      0   9.5000       0     0     0      0   \n",
       "1026        1026  27.000000      0      1  12.4750       1     0     0      0   \n",
       "898          898  19.000000      0      0   0.0000       0     0     0      0   \n",
       "1013        1013  29.881138      0      0   8.0500       1     0     0      0   \n",
       "\n",
       "       Dr  ...   Mrs   Ms   Rev   Sir   the Countess  Q  S  class-2  class-3  \\\n",
       "1226    0  ...     0    0     0     0              0  0  1        0        1   \n",
       "1269    0  ...     0    0     0     0              0  0  1        0        1   \n",
       "1026    0  ...     1    0     0     0              0  0  1        0        1   \n",
       "898     0  ...     0    0     0     0              0  0  1        0        1   \n",
       "1013    0  ...     0    0     0     0              0  0  1        0        1   \n",
       "\n",
       "      survived  \n",
       "1226         0  \n",
       "1269         0  \n",
       "1026         1  \n",
       "898          0  \n",
       "1013         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from tqdm import tqdm\n",
    "the_path = Path(os.getcwd())\n",
    "the_path = the_path.parents[1];\n",
    "# t_data = pd.read_csv(\"..\\..\\Python_Cleaner\\titanic_numerical_clean._With_Headers.csv\")\n",
    "# t_data.head()\n",
    "the_path = the_path / 'Python_Cleaner' / 'titanic_numerical_clean._With_Headers.csv'\n",
    "data = pd.read_csv(the_path, sep=\",\", header=0)\n",
    "data = data.sample(frac=1) # reshuffle all the rows.\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnamed:0 if present\n",
    "This is a lefot over of index of the pandas export of the project Python_cleaner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in data.columns:\n",
    "    del data['Unnamed: 0']\n",
    "data.head()\n",
    "\n",
    "y = data.pop('survived')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for the best accuracy with 10-Fold CV (Without scaling)\n",
    "\n",
    "Create the data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_np_array = np.array(X)\n",
    "y_np_array = np.array(y)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "#for each fold. train the model and get the accuracy.\n",
    "features_len = len(X_np_array[0])\n",
    "\n",
    "\n",
    "# from 1 to 5 hidden layers\n",
    "# from features_len -5 to features_len +5\n",
    "# calculate the accuracy across the 5_folds each.\n",
    "def evaluate(x_input, y_input, scale = False):\n",
    "    pbar = tqdm(total=(5*11))\n",
    "    \n",
    "    results = np.zeros([5, 11]) \n",
    "    mean_Accuracy = 0\n",
    "    for hidden_layers_num in range(1,6):\n",
    "        for neurons in range(features_len-5, features_len+6):\n",
    "            hidden_layers = []\n",
    "            for additional in range(1,hidden_layers_num+1):\n",
    "                hidden_layers.append(neurons)\n",
    "            hidden_layers= tuple(hidden_layers)\n",
    "            for train, test in kf.split(x_input):\n",
    "                X_train, X_test, y_train, y_test = x_input[train], x_input[test], y_input[train], y_input[test]\n",
    "                clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                                hidden_layer_sizes=hidden_layers, random_state=1, max_iter=1000)\n",
    "                \n",
    "                if scale:\n",
    "                    scaler = skl.preprocessing.StandardScaler().fit(X_train)\n",
    "                    X_train = scaler.transform(X_train)\n",
    "                    X_test = scaler.transform(X_test)\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                comparison = (clf.predict(X_test) == y_test)\n",
    "                accuracy = np.sum(comparison) / len(comparison) \n",
    "                mean_Accuracy += accuracy\n",
    "\n",
    "            results[hidden_layers_num-1][neurons-(features_len )+5] = mean_Accuracy / 10\n",
    "            mean_Accuracy = 0\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    return results\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev1_result = evaluate(X_np_array,y_np_array,null)\n",
    "            \n",
    "ev1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do evalutations on which layers size and number of neurons should be used.\n",
    "\n",
    "Randomly choos XX based on YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:07<06:20,  7.05s/it]\u001b[A\n",
      "  4%|▎         | 2/55 [00:14<06:16,  7.11s/it]\u001b[A\n",
      "  5%|▌         | 3/55 [00:21<06:12,  7.16s/it]\u001b[A\n",
      "  7%|▋         | 4/55 [00:26<05:36,  6.60s/it]\u001b[A\n",
      "  9%|▉         | 5/55 [00:33<05:23,  6.47s/it]\u001b[A\n",
      " 11%|█         | 6/55 [00:39<05:13,  6.40s/it]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:45<04:59,  6.24s/it]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:52<05:07,  6.55s/it]\u001b[A\n",
      " 16%|█▋        | 9/55 [01:04<06:24,  8.36s/it]\u001b[A\n",
      " 18%|█▊        | 10/55 [01:14<06:34,  8.76s/it]\u001b[A\n",
      " 20%|██        | 11/55 [01:24<06:38,  9.05s/it]\u001b[A\n",
      " 22%|██▏       | 12/55 [01:35<07:00,  9.77s/it]\u001b[A\n",
      " 24%|██▎       | 13/55 [01:46<06:59,  9.98s/it]\u001b[A\n",
      " 25%|██▌       | 14/55 [02:03<08:21, 12.24s/it]\u001b[A\n",
      " 27%|██▋       | 15/55 [02:25<09:57, 14.95s/it]\u001b[A\n",
      " 29%|██▉       | 16/55 [02:37<09:11, 14.14s/it]\u001b[A\n",
      " 31%|███       | 17/55 [02:52<09:11, 14.52s/it]\u001b[A\n",
      " 33%|███▎      | 18/55 [03:02<07:59, 12.96s/it]\u001b[A\n",
      " 35%|███▍      | 19/55 [03:11<07:05, 11.82s/it]\u001b[A\n",
      " 36%|███▋      | 20/55 [03:20<06:29, 11.12s/it]\u001b[A\n",
      " 38%|███▊      | 21/55 [03:29<05:49, 10.28s/it]\u001b[A\n",
      " 40%|████      | 22/55 [03:38<05:34, 10.13s/it]\u001b[A\n",
      " 42%|████▏     | 23/55 [03:54<06:13, 11.66s/it]\u001b[A\n",
      " 44%|████▎     | 24/55 [04:11<06:55, 13.41s/it]\u001b[A\n",
      " 45%|████▌     | 25/55 [04:25<06:45, 13.52s/it]\u001b[A\n",
      " 47%|████▋     | 26/55 [04:37<06:17, 13.02s/it]\u001b[A\n",
      " 49%|████▉     | 27/55 [04:52<06:25, 13.77s/it]\u001b[A\n",
      " 51%|█████     | 28/55 [05:09<06:32, 14.54s/it]\u001b[A\n",
      " 53%|█████▎    | 29/55 [05:23<06:16, 14.49s/it]\u001b[A\n",
      " 55%|█████▍    | 30/55 [05:37<05:58, 14.33s/it]\u001b[A\n",
      " 56%|█████▋    | 31/55 [05:52<05:52, 14.68s/it]\u001b[A\n",
      " 58%|█████▊    | 32/55 [06:13<06:17, 16.42s/it]\u001b[A\n",
      " 60%|██████    | 33/55 [06:31<06:14, 17.02s/it]\u001b[A\n",
      " 62%|██████▏   | 34/55 [07:01<07:17, 20.84s/it]\u001b[A\n",
      " 64%|██████▎   | 35/55 [07:22<06:55, 20.75s/it]\u001b[A\n",
      " 65%|██████▌   | 36/55 [07:41<06:26, 20.34s/it]\u001b[A\n",
      " 67%|██████▋   | 37/55 [08:04<06:20, 21.13s/it]\u001b[A\n",
      " 69%|██████▉   | 38/55 [08:30<06:22, 22.50s/it]\u001b[A\n",
      " 71%|███████   | 39/55 [08:50<05:51, 21.98s/it]\u001b[A\n",
      " 73%|███████▎  | 40/55 [09:21<06:09, 24.65s/it]\u001b[A\n",
      " 75%|███████▍  | 41/55 [09:52<06:08, 26.33s/it]\u001b[A\n",
      " 76%|███████▋  | 42/55 [10:28<06:21, 29.32s/it]\u001b[A\n",
      " 78%|███████▊  | 43/55 [11:13<06:48, 34.01s/it]\u001b[A\n",
      " 80%|████████  | 44/55 [11:43<06:02, 32.95s/it]\u001b[A\n",
      " 82%|████████▏ | 45/55 [12:26<05:59, 36.00s/it]\u001b[A\n",
      " 84%|████████▎ | 46/55 [13:22<06:18, 42.03s/it]\u001b[A\n",
      " 85%|████████▌ | 47/55 [14:25<06:26, 48.28s/it]\u001b[A\n",
      " 87%|████████▋ | 48/55 [14:59<05:06, 43.76s/it]\u001b[A\n",
      " 89%|████████▉ | 49/55 [15:35<04:09, 41.59s/it]\u001b[A/home/michalkb/miniconda3/envs/PythonNN/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      " 91%|█████████ | 50/55 [16:22<03:35, 43.14s/it]\u001b[A/home/michalkb/miniconda3/envs/PythonNN/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      " 93%|█████████▎| 51/55 [17:08<02:56, 44.01s/it]\u001b[A\n",
      " 95%|█████████▍| 52/55 [18:02<02:20, 46.98s/it]\u001b[A\n",
      " 96%|█████████▋| 53/55 [18:50<01:34, 47.27s/it]\u001b[A\n",
      " 98%|█████████▊| 54/55 [19:31<00:45, 45.53s/it]\u001b[A/home/michalkb/miniconda3/envs/PythonNN/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "100%|██████████| 55/55 [20:18<00:00, 22.16s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80672343, 0.80366412, 0.80367587, 0.80749266, 0.80597181,\n",
       "        0.80673517, 0.80596594, 0.80519671, 0.80902525, 0.8067293 ,\n",
       "        0.81436289],\n",
       "       [0.80749266, 0.80902525, 0.80520846, 0.80977686, 0.8075044 ,\n",
       "        0.81130358, 0.80290076, 0.81209043, 0.8113212 , 0.81055784,\n",
       "        0.81207868],\n",
       "       [0.80519084, 0.80978274, 0.8067293 , 0.80747504, 0.80747504,\n",
       "        0.80977686, 0.80366412, 0.81667645, 0.80826189, 0.81056371,\n",
       "        0.80445097],\n",
       "       [0.80826776, 0.80062243, 0.81207868, 0.80979448, 0.80594833,\n",
       "        0.80978861, 0.80520258, 0.81131533, 0.80214915, 0.80825602,\n",
       "        0.80443922],\n",
       "       [0.8067293 , 0.79755725, 0.80749853, 0.8105461 , 0.80978274,\n",
       "        0.80519084, 0.80825602, 0.80214915, 0.80673517, 0.80749853,\n",
       "        0.80596594]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_input =skl.preprocessing.scale(X)\n",
    "stuff = evaluate(X_input,y_np_array,True)\n",
    "            \n",
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806723</td>\n",
       "      <td>0.803664</td>\n",
       "      <td>0.803676</td>\n",
       "      <td>0.807493</td>\n",
       "      <td>0.805972</td>\n",
       "      <td>0.806735</td>\n",
       "      <td>0.805966</td>\n",
       "      <td>0.805197</td>\n",
       "      <td>0.809025</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.814363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807493</td>\n",
       "      <td>0.809025</td>\n",
       "      <td>0.805208</td>\n",
       "      <td>0.809777</td>\n",
       "      <td>0.807504</td>\n",
       "      <td>0.811304</td>\n",
       "      <td>0.802901</td>\n",
       "      <td>0.812090</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.810558</td>\n",
       "      <td>0.812079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.807475</td>\n",
       "      <td>0.807475</td>\n",
       "      <td>0.809777</td>\n",
       "      <td>0.803664</td>\n",
       "      <td>0.816676</td>\n",
       "      <td>0.808262</td>\n",
       "      <td>0.810564</td>\n",
       "      <td>0.804451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808268</td>\n",
       "      <td>0.800622</td>\n",
       "      <td>0.812079</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>0.805948</td>\n",
       "      <td>0.809789</td>\n",
       "      <td>0.805203</td>\n",
       "      <td>0.811315</td>\n",
       "      <td>0.802149</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>0.804439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.797557</td>\n",
       "      <td>0.807499</td>\n",
       "      <td>0.810546</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>0.802149</td>\n",
       "      <td>0.806735</td>\n",
       "      <td>0.807499</td>\n",
       "      <td>0.805966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.806723  0.803664  0.803676  0.807493  0.805972  0.806735  0.805966   \n",
       "1  0.807493  0.809025  0.805208  0.809777  0.807504  0.811304  0.802901   \n",
       "2  0.805191  0.809783  0.806729  0.807475  0.807475  0.809777  0.803664   \n",
       "3  0.808268  0.800622  0.812079  0.809794  0.805948  0.809789  0.805203   \n",
       "4  0.806729  0.797557  0.807499  0.810546  0.809783  0.805191  0.808256   \n",
       "\n",
       "          7         8         9        10  \n",
       "0  0.805197  0.809025  0.806729  0.814363  \n",
       "1  0.812090  0.811321  0.810558  0.812079  \n",
       "2  0.816676  0.808262  0.810564  0.804451  \n",
       "3  0.811315  0.802149  0.808256  0.804439  \n",
       "4  0.802149  0.806735  0.807499  0.805966  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocastic_optimizer_Data = pd.DataFrame(stuff)\n",
    "stocastic_optimizer_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
