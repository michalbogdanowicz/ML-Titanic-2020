http://www.cs.rtu.lv/jekabsons/regression.html

Steps to build a random forest:

1) split data in training and test

2) Choose best attributes and their numeric tresholds to maximizes the information gain (IG).
IG is computed by looking at entropy of the class distribution before and after the splitting.

1.1) Use mean as a splitting point (numerical data)

1.2) Stop grow tree when attributes are finished or when available data is < 4% ot dataset to reduce overfitting